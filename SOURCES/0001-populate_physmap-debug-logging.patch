From 33b41c356bde414b36c6344f06d28961513d4384 Mon Sep 17 00:00:00 2001
From: Andrii Sultanov <andriy.sultanov@vates.tech>
Date: Fri, 7 Nov 2025 09:28:21 +0000
Subject: [PATCH] populate_physmap debug logging

Signed-off-by: Andrii Sultanov <andriy.sultanov@vates.tech>
---
 xen/arch/arm/mmu/p2m.c | 24 ++++++++++++++++++++++
 xen/common/memory.c    | 45 +++++++++++++++++++++++++++++++++---------
 2 files changed, 60 insertions(+), 9 deletions(-)

diff --git a/xen/arch/arm/mmu/p2m.c b/xen/arch/arm/mmu/p2m.c
index 1725cca649..4fe9a0dbce 100644
--- a/xen/arch/arm/mmu/p2m.c
+++ b/xen/arch/arm/mmu/p2m.c
@@ -983,11 +983,16 @@ static int __p2m_set_entry(struct p2m_domain *p2m,
      * 4K - 2M - 1G mapping.
      */
     ASSERT(target > 0 && target <= 3);
+    printk("__p2m_set_entry inside\n");
 
     table = p2m_get_root_pointer(p2m, sgfn);
     if ( !table )
+    {
+        printk("__p2m_set_entry: table invalid\n");
         return -EINVAL;
+    }
 
+    printk("__p2m_set_entry: stage0\n");
     for ( level = P2M_ROOT_LEVEL; level < target; level++ )
     {
         /*
@@ -1006,6 +1011,7 @@ static int __p2m_set_entry(struct p2m_domain *p2m,
              * page table. In this case, just ignore it.
              */
             rc = removing_mapping ?  0 : -ENOENT;
+            printk("__p2m_set_entry: guest_table_map_failed\n");
             goto out;
         }
         else if ( rc != GUEST_TABLE_NORMAL_PAGE )
@@ -1014,6 +1020,7 @@ static int __p2m_set_entry(struct p2m_domain *p2m,
 
     entry = table + offsets[level];
 
+    printk("__p2m_set_entry: stage1\n");
     /*
      * If we are here with level < target, we must be at a leaf node,
      * and we need to break up the superpage.
@@ -1037,6 +1044,7 @@ static int __p2m_set_entry(struct p2m_domain *p2m,
             p2m_free_entry(p2m, split_pte, level);
 
             rc = -ENOMEM;
+            printk("__p2m_set_entry: p2m_split_superpage\n");
             goto out;
         }
 
@@ -1064,6 +1072,7 @@ static int __p2m_set_entry(struct p2m_domain *p2m,
 
         entry = table + offsets[level];
     }
+    printk("__p2m_set_entry: stage2\n");
 
     /*
      * We should always be there with the correct level because
@@ -1090,7 +1099,11 @@ static int __p2m_set_entry(struct p2m_domain *p2m,
      */
     rc = p2m_mem_access_radix_set(p2m, sgfn, a);
     if ( rc )
+    {
+        printk("__p2m_set_entry: p2m_mem_access_radix_set\n");
         goto out;
+    }
+    printk("__p2m_set_entry: stage3\n");
 
     /*
      * Always remove the entry in order to follow the break-before-make
@@ -1100,6 +1113,7 @@ static int __p2m_set_entry(struct p2m_domain *p2m,
     if ( lpae_is_valid(orig_pte) || removing_mapping )
         p2m_remove_pte(entry, p2m->clean_pte);
 
+    printk("__p2m_set_entry: stage4\n");
     if ( removing_mapping )
         /* Flush can be deferred if the entry is removed */
         p2m->need_flush |= !!lpae_is_valid(orig_pte);
@@ -1135,6 +1149,7 @@ static int __p2m_set_entry(struct p2m_domain *p2m,
         p2m->lowest_mapped_gfn = gfn_min(p2m->lowest_mapped_gfn, sgfn);
     }
 
+    printk("__p2m_set_entry: stage5\n");
     if ( is_iommu_enabled(p2m->domain) &&
          (lpae_is_valid(orig_pte) || lpae_is_valid(*entry)) )
     {
@@ -1160,6 +1175,7 @@ static int __p2m_set_entry(struct p2m_domain *p2m,
         p2m_free_entry(p2m, orig_pte, level);
 
 out:
+    printk("__p2m_set_entry: out\n");
     unmap_domain_page(table);
 
     return rc;
@@ -1174,6 +1190,7 @@ int p2m_set_entry(struct p2m_domain *p2m,
 {
     int rc = 0;
 
+    printk("p2m_set_entry {sgfn = %#"PRI_gfn", nr = %lu, smfn = %#"PRI_mfn"}\n", gfn_x(sgfn), nr, mfn_x(smfn));
     /*
      * Any reference taken by the P2M mappings (e.g. foreign mapping) will
      * be dropped in relinquish_p2m_mapping(). As the P2M will still
@@ -1181,12 +1198,16 @@ int p2m_set_entry(struct p2m_domain *p2m,
      * domain is dying.
      */
     if ( unlikely(p2m->domain->is_dying) )
+    {
+        printk("domain->is_dying\n");
         return -ENOMEM;
+    }
 
     while ( nr )
     {
         unsigned long mask;
         unsigned long order;
+        printk("nr = %ld\n", nr);
 
         /*
          * Don't take into account the MFN when removing mapping (i.e
@@ -1210,7 +1231,10 @@ int p2m_set_entry(struct p2m_domain *p2m,
 
         rc = __p2m_set_entry(p2m, sgfn, order, smfn, t, a);
         if ( rc )
+        {
+            printk("__p2m_set_entry break\n");
             break;
+        }
 
         sgfn = gfn_add(sgfn, (1 << order));
         if ( !mfn_eq(smfn, INVALID_MFN) )
diff --git a/xen/common/memory.c b/xen/common/memory.c
index 1f0a9d7e5f..77bab8956a 100644
--- a/xen/common/memory.c
+++ b/xen/common/memory.c
@@ -164,13 +164,22 @@ static void populate_physmap(struct memop_args *a)
     bool need_tlbflush = false;
     uint32_t tlbflush_timestamp = 0;
 
+    printk( "populate_physmap {nr_extents = %d, extent_order = %d, memflags = %d, nr_done = %d, preempted = %d}\n",
+             a->nr_extents, a->extent_order, a->memflags, a->nr_done, a->preempted);
+
     if ( !guest_handle_subrange_okay(a->extent_list, a->nr_done,
                                      a->nr_extents-1) )
+    {
+        printk("guest_handle_subrange is not okay\n");
         return;
+    }
 
     if ( a->extent_order > (a->memflags & MEMF_populate_on_demand ? MAX_ORDER :
                             max_order(curr_d)) )
+    {
+        printk("extent order too big\n");
         return;
+    }
 
     if ( unlikely(!d->creation_finished) )
     {
@@ -196,15 +205,20 @@ static void populate_physmap(struct memop_args *a)
     for ( i = a->nr_done; i < a->nr_extents; i++ )
     {
         mfn_t mfn;
+        printk("populate_physmap: i = %d\n", i);
 
         if ( i != a->nr_done && hypercall_preempt_check() )
         {
             a->preempted = 1;
+            printk("populate_physmap: preempted\n");
             goto out;
         }
 
         if ( unlikely(__copy_from_guest_offset(&gpfn, a->extent_list, i, 1)) )
+        {
+            printk("populate_physmap: copy_from_guest_offset\n");
             goto out;
+        }
 
         if ( a->memflags & MEMF_populate_on_demand )
         {
@@ -228,7 +242,7 @@ static void populate_physmap(struct memop_args *a)
                 {
                     if ( !mfn_valid(mfn) )
                     {
-                        gdprintk(XENLOG_INFO, "Invalid mfn %#"PRI_mfn"\n",
+                        printk("Invalid mfn %#"PRI_mfn"\n",
                                  mfn_x(mfn));
                         goto out;
                     }
@@ -236,8 +250,7 @@ static void populate_physmap(struct memop_args *a)
                     page = mfn_to_page(mfn);
                     if ( !get_page(page, d) )
                     {
-                        gdprintk(XENLOG_INFO,
-                                 "mfn %#"PRI_mfn" doesn't belong to d%d\n",
+                        printk("mfn %#"PRI_mfn" doesn't belong to d%d\n",
                                   mfn_x(mfn), d->domain_id);
                         goto out;
                     }
@@ -254,8 +267,7 @@ static void populate_physmap(struct memop_args *a)
                  */
                 if ( a->extent_order != 0 )
                 {
-                    gdprintk(XENLOG_WARNING,
-                             "Cannot allocate static order-%u pages for %pd\n",
+                    printk("Cannot allocate static order-%u pages for %pd\n",
                              a->extent_order, d);
                     goto out;
                 }
@@ -263,8 +275,7 @@ static void populate_physmap(struct memop_args *a)
                 mfn = acquire_reserved_page(d, a->memflags);
                 if ( mfn_eq(mfn, INVALID_MFN) )
                 {
-                    gdprintk(XENLOG_WARNING,
-                             "%pd: failed to retrieve a reserved page\n",
+                    printk( "%pd: failed to retrieve a reserved page\n",
                              d);
                     goto out;
                 }
@@ -275,8 +286,7 @@ static void populate_physmap(struct memop_args *a)
 
                 if ( unlikely(!page) )
                 {
-                    gdprintk(XENLOG_INFO,
-                             "Could not allocate order=%u extent: id=%d memflags=%#x (%u of %u)\n",
+                    printk( "Could not allocate order=%u extent: id=%d memflags=%#x (%u of %u)\n",
                              a->extent_order, d->domain_id, a->memflags,
                              i, a->nr_extents);
                     goto out;
@@ -293,16 +303,23 @@ static void populate_physmap(struct memop_args *a)
             }
 
             if ( guest_physmap_add_page(d, _gfn(gpfn), mfn, a->extent_order) )
+            {
+                printk("populate_physmap: guest_physmap_add_page\n");
                 goto out;
+            }
 
             if ( !paging_mode_translate(d) &&
                  /* Inform the domain of the new page's machine address. */
                  unlikely(__copy_mfn_to_guest_offset(a->extent_list, i, mfn)) )
+            {
+                printk("populate_physmap: paging_mode_translate && copy\n");
                 goto out;
+            }
         }
     }
 
 out:
+    printk("populate_physmap: out\n");
     if ( need_tlbflush )
         filtered_flush_tlb_mask(tlbflush_timestamp);
 
@@ -1406,19 +1423,29 @@ long do_memory_op(unsigned long cmd, XEN_GUEST_HANDLE_PARAM(void) arg)
     case XENMEM_increase_reservation:
     case XENMEM_decrease_reservation:
     case XENMEM_populate_physmap:
+
         if ( copy_from_guest(&reservation, arg, 1) )
             return start_extent;
 
         /* Is size too large for us to encode a continuation? */
         if ( reservation.nr_extents > (UINT_MAX >> MEMOP_EXTENT_SHIFT) )
+        {
+            printk("reservation.nr_extents > (uint_max>>shift)\n");
             return start_extent;
+        }
 
         if ( unlikely(start_extent >= reservation.nr_extents) )
+        {
+            printk("start_extent >= reservation.nr_extents\n");
             return start_extent;
+        }
 
         d = rcu_lock_domain_by_any_id(reservation.domid);
         if ( d == NULL )
+        {
+            printk("rcu_lock?\n");
             return start_extent;
+        }
         args.domain = d;
 
         if ( construct_memop_from_reservation(&reservation, &args) )
